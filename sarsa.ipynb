{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>SARSA (State-Action-Reward-State-Action/Estado-Ação-Recompensa-Estado-Ação)</h3>\n",
    "<p align=\"justify\">O SARSA é uma adaptação do Q-Learning, porém o Q-Learning é conhecido como algoritmo ganancioso por que buscará sempre a recompensa máxima para o estado seguinte, enquanto que o SARSA é um algoritmo conservador que irá evitar recompensas máximas que possam colocá-lo em um caminho de recompensas menores no futuro.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Primeira Alternativa de Construção (forma completa)</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Exemplo com Q-Learning</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'C', 'D']\n"
     ]
    }
   ],
   "source": [
    "from Neuraline.ArtificialIntelligence.MachineLearning.ReinforcementLearning.q_learning import QLearning\n",
    "q_learning = QLearning()\n",
    "\n",
    "inputs = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n",
    "q_learning.addActions(actions=inputs)\n",
    "q_learning.addStateQuality(action='A', quality=1)\n",
    "q_learning.addStateQuality(action='A', quality=2)\n",
    "q_learning.addStateQuality(action='A', quality=0)\n",
    "q_learning.addStateQuality(action='B', quality=5)\n",
    "q_learning.addStateQuality(action='B', quality=1)\n",
    "q_learning.addStateQuality(action='B', quality=2)\n",
    "q_learning.addStateQuality(action='C', quality=2)\n",
    "q_learning.addStateQuality(action='C', quality=4)\n",
    "q_learning.addStateQuality(action='C', quality=5)\n",
    "q_learning.addStateQuality(action='D', quality=4)\n",
    "q_learning.addStateQuality(action='D', quality=4)\n",
    "q_learning.addStateQuality(action='D', quality=7)\n",
    "q_learning.addStateQuality(action='E', quality=2)\n",
    "q_learning.addStateQuality(action='E', quality=1)\n",
    "q_learning.addStateQuality(action='E', quality=5)\n",
    "q_learning.addStateQuality(action='F', quality=2)\n",
    "q_learning.addStateQuality(action='F', quality=4)\n",
    "q_learning.addStateQuality(action='F', quality=3)\n",
    "q_learning.addStateQuality(action='G', quality=3)\n",
    "q_learning.addStateQuality(action='G', quality=3)\n",
    "q_learning.addStateQuality(action='G', quality=4)\n",
    "q_learning.addStateQuality(action='H', quality=2)\n",
    "q_learning.addStateQuality(action='H', quality=1)\n",
    "q_learning.addStateQuality(action='H', quality=5)\n",
    "result = q_learning.predict()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Exemplo com SARSA</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'D', 'D']\n"
     ]
    }
   ],
   "source": [
    "from Neuraline.ArtificialIntelligence.MachineLearning.ReinforcementLearning.sarsa import SARSA\n",
    "sarsa = SARSA()\n",
    "\n",
    "inputs = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n",
    "sarsa.addActions(actions=inputs)\n",
    "sarsa.addStateQuality(action='A', quality=1)\n",
    "sarsa.addStateQuality(action='A', quality=2)\n",
    "sarsa.addStateQuality(action='A', quality=0)\n",
    "sarsa.addStateQuality(action='B', quality=5)\n",
    "sarsa.addStateQuality(action='B', quality=1)\n",
    "sarsa.addStateQuality(action='B', quality=2)\n",
    "sarsa.addStateQuality(action='C', quality=2)\n",
    "sarsa.addStateQuality(action='C', quality=4)\n",
    "sarsa.addStateQuality(action='C', quality=5)\n",
    "sarsa.addStateQuality(action='D', quality=4)\n",
    "sarsa.addStateQuality(action='D', quality=4)\n",
    "sarsa.addStateQuality(action='D', quality=7)\n",
    "sarsa.addStateQuality(action='E', quality=2)\n",
    "sarsa.addStateQuality(action='E', quality=1)\n",
    "sarsa.addStateQuality(action='E', quality=5)\n",
    "sarsa.addStateQuality(action='F', quality=2)\n",
    "sarsa.addStateQuality(action='F', quality=4)\n",
    "sarsa.addStateQuality(action='F', quality=3)\n",
    "sarsa.addStateQuality(action='G', quality=3)\n",
    "sarsa.addStateQuality(action='G', quality=3)\n",
    "sarsa.addStateQuality(action='G', quality=4)\n",
    "sarsa.addStateQuality(action='H', quality=2)\n",
    "sarsa.addStateQuality(action='H', quality=1)\n",
    "sarsa.addStateQuality(action='H', quality=5)\n",
    "result = sarsa.predict()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Segunda Alternativa de Construção (forma resumida)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Neuraline.ArtificialIntelligence.MachineLearning.ReinforcementLearning.q_learning import QLearning\n",
    "from Neuraline.ArtificialIntelligence.MachineLearning.ReinforcementLearning.sarsa import SARSA\n",
    "q_learning, sarsa = QLearning(), SARSA()\n",
    "\n",
    "inputs = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n",
    "states = [[1, 2, 0], [5, 1, 2], [2, 4, 5], [4, 4, 7], [2, 1, 5], [2, 4, 3], [3, 3, 4], [2, 1, 5]]\n",
    "\n",
    "q_learning.fit(actions=inputs, states=states), sarsa.fit(actions=inputs, states=states)\n",
    "result_q_learning, result_sarsa = q_learning.predict(), sarsa.predict()\n",
    "\n",
    "print(f'Q-Learning: {result_q_learning}')\n",
    "print(f'SARSA: {result_sarsa}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Salvamento da Tabela Qualitativa</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tabela qualitativa salva com sucesso\n"
     ]
    }
   ],
   "source": [
    "if sarsa.saveQTable(url_path='qtable_sarsa.txt'): print('tabela qualitativa salva com sucesso')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Criação do Código/Game de Exemplo</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Neuraline.ArtificialIntelligence.MachineLearning.ReinforcementLearning.sarsa import SARSA\n",
    "sarsa = SARSA()\n",
    "if sarsa.generate_example('exemplo_sarsa01.py'): print('exemplo construído com sucesso')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
